---
title: "Dirichlet Regression Model (DirichletReg)"
author: "Mervin M Fansler"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document: 
    code_folding: show
    toc: true
    toc_float: true
---

# Purpose

Here we fit a Dirichlet regression model to partition coefficients (PCOs). The 
PCOs are then used assign a localization category. We characterize the model by 
the ability to accurately predict localization category. We expect that this should
improve over the previous logistic regression model, since it models the strength
of the localization rather than only the categorization.

# Initialization

## Libraries
```{r libs, message=FALSE, warning=FALSE}
library(magrittr)
library(tidyverse)
library(readxl)
library(DirichletReg)
library(caret)
```

## Parameters
```{r set_params}
set.seed(20220607)
N_STEPS=200

RDS_IN="data/df_tiger_clean.Rds"

LOC_COLORS=c("ER"="#4B74A6", "TG"="#E4E4CA", "CY"="#949494", "DF"="#CCCCCC")

COVARIATES=c(
    "Leb_HuR_CLIP", 
    "Muk_HuR_CLIP", 
    "CPE_annoUTR", 
    "CCCCCC_3UTR_num",
    "Pumilio_3UTR_num", 
    "PUM2_CLIP", 
    "KHSRP_CLIP", 
    "CPSF6_CLIP", 
    "TIS11B_CLIP", 
    "TIA1_L1_CLIP", 
    "PTBP1_CLIP", 
    "HNRNPC_CLIP",
    "CELF2_CLIP", 
    "HNRNPM_CLIP", 
    "HNRNPD_CLIP", 
    "Zhang_RBM15_RIP",
    "LIN28B_CLIP", 
    "IGF2BP3_CLIP", 
    "TARDBP_CLIP", 
    "TAF15_CLIP",
    "FUS_CLIP", 
    "METAP2_CLIP", 
    "DDX6_CLIP", 
    "EIF4A3_CLIP",
    "LARP4B_exon_CLIP", 
    "hnRNPK_CLIP", 
    "GEMIN5_CLIP", 
    "CSTF2T_CLIP",
    "DDX24_CLIP", 
    "PCBP2_CLIP", 
    "PUM_RIP12",
    "Anno_3UTR_length")

MIN_PCON_CY=1.15
MIN_PCON_ER=1.25
MIN_PCON_TG=1.30

MIN_PCON_DIFF=0.15
```

## Functions
Note that the `MEDIAN_*` variables must be set globally - which will be done later
in the document.

```{r methods}
assign_localization <- function (pco_cy, pco_er, pco_tg) {
    df_pcons <- tibble(pcon_CY=pco_cy / MEDIAN_PCO_CY,
                       pcon_ER=pco_er / MEDIAN_PCO_ER,
                       pcon_TG=pco_tg / MEDIAN_PCO_TG) %>%
        mutate(id=row_number()) %>%
        pivot_longer(cols=starts_with("pcon"), values_to="pcon",
                     names_to="compartment", names_prefix="pcon_") %>%
        group_by(id) %>%
        mutate(has_min_diff=pcon[order(pcon)[3]] - pcon[order(pcon)[2]] >= MIN_PCON_DIFF,
               max_compartment=compartment[order(pcon)[3]]) %>%
        ungroup() %>%
        pivot_wider(values_from="pcon",
                    names_from="compartment", names_prefix="pcon_") %>%
        mutate(n_enriched=as.integer(pcon_CY >= MIN_PCON_CY) + 
                   as.integer(pcon_ER >= MIN_PCON_ER) + 
                   as.integer(pcon_TG >= MIN_PCON_TG)) %>%
        mutate(category=case_when(
            n_enriched > 1 & has_min_diff ~ max_compartment,
            n_enriched > 1 & !has_min_diff ~ "DF", 
            pcon_TG >= MIN_PCON_TG ~ "TG",
            pcon_ER >= MIN_PCON_ER ~ "ER",
            pcon_CY >= MIN_PCON_CY ~ "CY",
            TRUE ~ "DF"
        ) %>% factor(levels=c("DF", "ER", "TG", "CY")))
    
    df_pcons$category
}
```

# Data
## Loading
```{r load_data, message=FALSE}
df_tiger <- readRDS(RDS_IN)
```

## Preprocessing
### Subset
```{r prepare_data}
df_data <- select(df_tiger, category, pco_tg, pco_er, pco_cy, all_of(COVARIATES))
```

### Reassign categories
```{r set_data_medians}
## use exact medians
MEDIAN_PCO_CY=median(df_data$pco_cy)
MEDIAN_PCO_ER=median(df_data$pco_er)
MEDIAN_PCO_TG=median(df_data$pco_tg)

df_data %<>% 
    mutate(category=assign_localization(pco_cy, pco_er, pco_tg))
```

Note that these categories do not correspond exactly to the received data. We hope 
to address this, but for now let's just note the amount of discrepancy by examining
the confusion matrix.

```{r conf_mat_assignments}
confusionMatrix(df_data$category, df_tiger$category)
```


### Imputing
```{r data_impute}
df_imputed <- df_data %>%
    mutate_at("Anno_3UTR_length", ~ ifelse(is.na(.x), median(.x, na.rm=TRUE), .x)) %>%
    mutate_at(-c(1,2,3,4), ~ ifelse(is.na(.x), 0, .x))
```

### Data Normalizing
```{r data_normalize}
df_scaled <- df_imputed %>%
    mutate_at(-c(1,2,3,4), ~ scale(sqrt(.x))[,1])
```

### Splitting
```{r data_split}
idx_train <- createDataPartition(df_scaled$category, p=0.8, list=FALSE)

df_train <- df_scaled[idx_train,]
df_test  <- df_scaled[-idx_train,]

full_join(count(df_train, category, name="n_train"),
          count(df_test, category, name="n_test"),
          by="category") %>%
    knitr::kable()

df_train_clean <- df_train[,-c(1,2,3,4)]
df_train_clean$Y <- DR_data(df_train[,c("pco_cy", "pco_er", "pco_tg")])

df_test_clean <- df_test[,-c(1,2,3,4)]
df_test_clean$Y <- DR_data(df_test[,c("pco_cy", "pco_er", "pco_tg")])
```

# Model Fitting
```{r fit_dirichlet_reg}
model_lin <- DirichReg(Y ~ ., data=df_train_clean, verbosity=TRUE)
```


```{r}
model_lin
```


```{r extract_coefs}
df_coefs <- coef(model_lin) %>% 
    map(as_tibble, rownames="variable") %>% 
    map2(names(.), ~ mutate(.x, component=.y)) %>% 
    do.call(what=rbind) %>% 
    mutate(component=toupper(str_extract(component, "(cy|er|tg)")))

df_coefs %>% 
    pivot_wider("variable", names_from="component", values_from="value") %>%
    arrange(-pmax(abs(CY), abs(ER), abs(TG))) %>%
    knitr::kable()
```


```{r plt_coefs_all, fig.height=10, fig.width=4}
df_coefs %>%
    filter(variable != "(Intercept)") %>%
    mutate(variable=fct_reorder(variable, abs(value), max)) %>%
    ggplot(aes(y=variable, x=value, fill=component)) +
    geom_vline(xintercept=0) +
    geom_bar(stat='identity', position='dodge', color='black', size=0.1, width=0.6) +
    scale_fill_manual(values=LOC_COLORS[-4]) +
    labs(x="Coefficient", y=NULL, fill="Category") +
    theme_light()
```

## Predicted Localization
### Train
```{r train_predictions}
df_fitted_train <- fitted(model_lin) %>% 
    as_tibble %>%
    mutate(predicted=assign_localization(pco_cy, pco_er, pco_tg),
           category=df_train$category)

df_fitted_train %$% confusionMatrix(predicted, category)

df_fitted_train %>%
    count(category, predicted) %>% 
    ggplot(aes(category, predicted, fill=n)) +
    geom_tile() + geom_text(aes(label=n)) +
    scale_fill_gradient(low="white") +
    labs(title="Training Set", x="True Category", y="Predicted Category") +
    theme_light()
```

### Test Set
```{r test_predictions}
df_fitted_test <- predict(model_lin, newdata=df_test_clean) %>%
    `colnames<-`(str_c("pco_", c("cy", "er", "tg"))) %>%
    as_tibble %>%
    mutate(predicted=assign_localization(pco_cy, pco_er, pco_tg),
           category=df_test$category)

df_fitted_test %$% confusionMatrix(predicted, category)

df_fitted_test %>%
    count(category, predicted) %>% 
    ggplot(aes(category, predicted, fill=n)) +
    geom_tile() + geom_text(aes(label=n)) +
    scale_fill_gradient(low="white") +
    labs(title="Test Set", x="True Category", y="Predicted Category") +
    theme_light()
```

# Conclusion

The Dirichlet regression model does not appear to show any improvement over the 
logistic regression model.

---

# Runtime Details
## Session Info
```{r sesh_info, echo=FALSE}
sessionInfo()
```

## Conda Environment
```{bash comment="", echo=FALSE}
if ! command -v conda &> /dev/null
then
  echo "Conda not detected."
elif [ -z "${CONDA_PREFIX}" ]
then
  echo "No active Conda environment."
else
  echo "## Conda Environment YAML"
  conda env export
fi
```
